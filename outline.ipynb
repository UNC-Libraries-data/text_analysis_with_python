{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analysis With Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction - Lorin\n",
    "\n",
    "To follow along...\n",
    "\n",
    "Packages that need to be installed\n",
    "\n",
    "pandas\n",
    "sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Packages often used for Text Analysis - Rolando\n",
    "- Directly related to Text Analysis\n",
    "    - NLTK\n",
    "    - spaCy\n",
    "    - Textblob\n",
    "    - Gensim\n",
    "    - Transformers\n",
    "\n",
    "- Useful tools for text analysis\n",
    "    - Pandas\n",
    "    - Scikit-Learn\n",
    "    - Matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-project 1: Word Frequencies (1:05) - Rolando\n",
    "\n",
    "#### Data: [Jane Eyre - Charlotte BrontÃ«](https://www.gutenberg.org/files/1260/1260-h/1260-h.htm)\n",
    "#### Tools: NLTK, Scitkit-learn, Pandas\n",
    "#### Method: Simple N-grams (Document vs Chapters), Maybe TF-IDF, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-project 2: Classification (1:15) - Lorin\n",
    "\n",
    "#### Data: [On the Books Laws](https://cdr.lib.unc.edu/concern/data_sets/v405sk89q?locale=en)\n",
    "#### Tools: Scitkit-learn, Pandas, \n",
    "#### Methods: Supervised (Jim Crow vs. Non-Jim Crow) vs Unsupervised (Topic-modeling)\n",
    "#### Helpful: [Comparing classifiers](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bring in labeled training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1785 entries, 0 to 1784\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   id                      1785 non-null   object\n",
      " 1   source                  1785 non-null   object\n",
      " 2   jim_crow                1785 non-null   int64 \n",
      " 3   chapter_num             1785 non-null   int64 \n",
      " 4   section_num             1785 non-null   int64 \n",
      " 5   chapter_text            1785 non-null   object\n",
      " 6   section_text            1785 non-null   object\n",
      " 7   year                    1785 non-null   int64 \n",
      " 8   type_private laws       1785 non-null   int64 \n",
      " 9   type_public laws        1785 non-null   int64 \n",
      " 10  type_public local laws  1785 non-null   int64 \n",
      " 11  type_session laws       1785 non-null   int64 \n",
      "dtypes: int64(8), object(4)\n",
      "memory usage: 167.5+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"datasets/otb_training_set.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Includes 512 examples of Jim Crow laws and 1273 non Jim Crow laws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1273\n",
       "1     512\n",
       "Name: jim_crow, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.jim_crow.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laws were labeled as Jim Crow or Not Jim Crow according to scholarly works (Pauli Murray, Richard Paschal) and experts at UNC (William Sturkey, among others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "project experts    1673\n",
       "paschal              74\n",
       "murray               38\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to pick a target for our classification, aka the \"output\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[\"jim_crow\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What features do we want to train the models on? They will be our \"inputs\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1785 entries, 0 to 1784\n",
      "Data columns (total 6 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   section_text            1785 non-null   object\n",
      " 1   year                    1785 non-null   int64 \n",
      " 2   type_private laws       1785 non-null   uint8 \n",
      " 3   type_public laws        1785 non-null   uint8 \n",
      " 4   type_public local laws  1785 non-null   uint8 \n",
      " 5   type_session laws       1785 non-null   uint8 \n",
      "dtypes: int64(1), object(1), uint8(4)\n",
      "memory usage: 35.0+ KB\n"
     ]
    }
   ],
   "source": [
    "features = df.loc[:, \"section_text\" : \"type_session laws\"]\n",
    "features.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use train-test-split to separate data into training and testing sets. 80% will be training, 20% will be testing - set by test_size = 0.2.  Data is chosen for the different sets at random, so random_state allows us all to get the same results. X_train and X_test include the inputs. y_train and y_test include the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.2, random_state = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-project 3: Sentiment Analysis (1:35) - Rolando\n",
    "\n",
    "#### Data: [Chaptgpt Sentiment Analysis](https://www.kaggle.com/datasets/charunisa/chatgpt-sentiment-analysis)\n",
    "#### Tools: Textblob, NLTK, spaCy, Transformers\n",
    "#### Methods: Dictionary (+ rule-based) vs. Transformer-based approach"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
